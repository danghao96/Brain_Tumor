{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Muah5Pdk4HUN"
   },
   "source": [
    "### 1. Classic CNN Architectures\n",
    "These models are early milestones in deep learning, laying the groundwork for many subsequent innovations.\n",
    "\n",
    "- **AlexNet**: A pioneering deep convolutional neural network, known for using ReLU activation and dropout to prevent overfitting.\n",
    "- **VGG**: Improves performance with smaller convolutional filters and deeper network structures, simple architecture but large in parameters.\n",
    "\n",
    "### 2. Residual Networks\n",
    "Introduced residual connections to build deeper networks, addressing the challenges in training deep architectures.\n",
    "\n",
    "- **ResNet**: Solves deep network degradation issues with skip connections.\n",
    "- **ResNeXt**: Based on ResNet, introduces grouped convolutions, enhancing network scalability.\n",
    "- **Wide ResNet**: A ResNet variant that improves performance by increasing the network's width.\n",
    "\n",
    "### 3. Inception Series\n",
    "Effectively controls computational resources using multi-scale convolutional kernels.\n",
    "\n",
    "- **GoogLeNet (Inception V1)**: Famous for its “Inception” module, using multi-scale convolutions.\n",
    "- **Inception V3**: An improved version of the Inception model, incorporating batch normalization and label smoothing.\n",
    "\n",
    "### 4. Mobile and Lightweight Architectures\n",
    "Designed for mobile and embedded devices, emphasizing efficiency and compactness.\n",
    "\n",
    "- **MobileNet V2**: Introduces inverted residuals and linear bottlenecks.\n",
    "- **MobileNet V3**: Combines NAS and NetAdapt techniques for higher efficiency.\n",
    "- **ShuffleNet V2**: Employs channel shuffle operations, lightweight.\n",
    "- **SqueezeNet**: Extremely small model size, uses Fire modules.\n",
    "\n",
    "### 5. Efficient and Adaptive Networks\n",
    "Use advanced techniques and design philosophies for improved efficiency and performance.\n",
    "\n",
    "- **DenseNet**: Connects each layer to every other layer, enhancing feature propagation and reuse.\n",
    "- **EfficientNet**: Scales depth, width, and resolution simultaneously.\n",
    "- **EfficientNetV2**: An improved version of EfficientNet, optimized for faster training speed.\n",
    "- **RegNet**: Simplifies network architecture search with regularized design.\n",
    "- **MNASNet**: Automatically designed through neural architecture search, focusing on mobile efficiency.\n",
    "\n",
    "### 6. Transformer and Vision Transformer\n",
    "Applies the Transformer architecture to visual tasks, emphasizing global feature learning.\n",
    "\n",
    "- **VisionTransformer (ViT)**: Uses image patches as input units for efficient global feature learning.\n",
    "- **SwinTransformer**: Improves efficiency with a moving window approach.\n",
    "\n",
    "### 7. Emerging and Hybrid Architectures\n",
    "Latest network architectures combining different technologies and concepts.\n",
    "\n",
    "- **ConvNeXt**: Optimizes traditional convolutional network design, inspired by Transformer concepts.\n",
    "- **MaxVit**: Combines MaxPool and Vision Transformer architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQXxaViUG3bI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnbEHIlN9jA_"
   },
   "outputs": [],
   "source": [
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, root, phase, augment):\n",
    "        self.img_dir = root\n",
    "        self.labels = []\n",
    "        self.phase = phase\n",
    "        self.augment = augment\n",
    "        self.label_map = {'normal': 0, 'glioma_tumor': 1, 'meningioma_tumor': 2, 'pituitary_tumor': 3}\n",
    "\n",
    "        num_samples={'normal': 400, 'glioma_tumor': 800, 'meningioma_tumor': 800, 'pituitary_tumor': 800}\n",
    "        data_split = {'train': 0.5, 'val': 0.25, 'test': 0.25}\n",
    "        for class_dir in os.listdir(self.img_dir):\n",
    "            class_path = os.path.join(self.img_dir, class_dir)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            files = os.listdir(class_path)\n",
    "            random.shuffle(files)\n",
    "\n",
    "            num_to_select = num_samples[class_dir]\n",
    "            subset = files[:num_to_select]\n",
    "            split_idx = int(len(subset) * data_split[phase])\n",
    "            if phase == 'train':\n",
    "                selected_files = subset[:split_idx]\n",
    "            elif phase == 'val':\n",
    "                selected_files = subset[split_idx:2*split_idx]\n",
    "            elif phase == 'test':\n",
    "                selected_files = subset[2*split_idx:]\n",
    "\n",
    "            for file_name in selected_files:\n",
    "                self.labels.append((os.path.join(class_dir, file_name), class_dir))\n",
    "\n",
    "        if phase == 'train' or phase == 'test':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
    "                transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1)]),\n",
    "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))]),\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = transforms.Compose([])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels[idx][0])\n",
    "        image = read_image(img_path).to(torch.float)\n",
    "        if self.augment:\n",
    "            image = self.transforms(image)\n",
    "        label = self.label_map[self.labels[idx][1]]\n",
    "        label = torch.tensor(label)\n",
    "        return image, label\n",
    "\n",
    "def test_dataloader(dataloader):\n",
    "    for images, labels in dataloader:\n",
    "        print(\"Batch size:\", len(images))\n",
    "        print(\"Image size:\", images[0].shape)\n",
    "        print(\"Labels:\", labels)\n",
    "        break\n",
    "\n",
    "root = \"./project/Data\"\n",
    "batch_size = 16\n",
    "train_data = BrainDataset(root=root, phase='train')\n",
    "val_data = BrainDataset(root=root, phase='val')\n",
    "test_data = BrainDataset(root=root, phase='test')\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJPEQG8YmjrZ",
    "outputId": "b0b3af1c-ed2f-4004-a6ff-a4d2beb35f09"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "from torch.backends import cpu\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += int(torch.sum(preds == labels.data))\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects / len(dataloader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += int(torch.sum(preds == labels.data))\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects / len(dataloader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "import copy\n",
    "\n",
    "def train_loop(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, early_stop_patience):\n",
    "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = float('inf')\n",
    "    best_train_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Check if the validation loss improved\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Check if training should be stopped\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(\"Validation loss has not improved for {:d} epochs. Stopping training...\".format(early_stop_patience))\n",
    "            break\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_losses, train_accs, val_losses, val_accs\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, test_loader, num_tests=5):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "\n",
    "    all_preds = {}\n",
    "\n",
    "    for _ in range(num_tests):\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size(0)):\n",
    "                if (i, j) not in all_preds:\n",
    "                    all_preds[(i, j)] = []\n",
    "                all_preds[(i, j)].append(preds[j].item())\n",
    "\n",
    "    for (i, j), preds in all_preds.items():\n",
    "        label = test_loader.dataset[i][1]\n",
    "        avg_pred = np.round(np.mean(preds)).astype(int)\n",
    "        running_corrects += int(avg_pred == label)\n",
    "\n",
    "    epoch_acc = running_corrects / len(test_loader.dataset)\n",
    "    return epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uGLDXWsKXwyS",
    "outputId": "e45bffff-ecd3-46f0-8ee6-99736c2b3cdc"
   },
   "outputs": [],
   "source": [
    "model = models.efficientnet_v2_m(weights='DEFAULT', num_classes=1000)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 4)\n",
    "model = model.to(device)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 1000\n",
    "early_stop_patience = 10\n",
    "model, train_losses, train_accs, val_losses, val_accs = train_loop(model, train_loader, val_loader, criterion, optimizer, num_epochs=num_epochs, device=device, early_stop_patience=early_stop_patience)\n",
    "actual_epochs = len(train_losses) + 1\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, actual_epochs), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, actual_epochs), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Val Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, actual_epochs), train_accs, label='Train Acc')\n",
    "plt.plot(range(1, actual_epochs), val_accs, label='Val Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train and Val Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RYP6QQ3b4Hw2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
